# {{cookiecutter.project_name}}

Deployment information.

1 Development workflows
=======================

1.1 Start project
-----------------

Using the power of `cookiecutter`, this single command provides a pretty solid starting point for any new project.

```bash
cookiecutter gh:eliavw/cookiecutter-datascience
```

1.2 git
-------

Version control goes without saying. For the local repository, do;

```bash
git init
git add .
git commit -m "First commit"
```

For the remote repository, do;

```bash
git remote add origin git@github.com:{{cookiecutter.github_username}}/{{cookiecutter.project_name}}.git
git remote -v
git push origin master
```

And that's it for git.

1.3 CI (Travis)
---------------

Do not allow yourself to proceed without at least accumulating some tests. Therefore, we've set out to intigrate CI (i.e. Travis) right from the start.

Follow these steps:

1. Go to https://travis-ci.com/{{cookiecutter.github_username}}/{{cookiecutter.project_name}}
2. See if it ran.

**Note:** This depends on your `environment,yaml` file. Travis installs your abstract dependencies and then runs your tests. This is an additional test to verify if your abstract dependencies are sensible. Absolute dependencies are basically cute nothings, that are easily generated by conda. They can be useful reproducible tools for a single machine.


1.4 Conda environments
----------------------
This is a personal preference. This cookiecutter is set up to accomodate conda environments, since they are quite useful for datascience projects. The main message would be `for local dependency/package managment, we use conda and nothing else`


2 Distribution workflows
========================

This part is about publishing your project on PyPi.

2.1 Pypi
--------

Follow these steps

2.2 Docs
--------
Every project needs documentation.

2.3 Docker
----------

2.4 Singularity
---------------



Deployment Information
======================

We use git for versioning and conda for package managment.

Version Control
---------------

First, create an empty repository on github, e.g.: `eliavw/{{cookiecutter.project_name}}`.

Then, add the following lines to `.gitignore`,

```bash
.ipynb_checkpoints
```

to ignore the useless checkpoint folders.


```bash
git init
git add .
git commit -m "First commit"
git remote add origin git@github.com:eliavw/{{cookiecutter.project_name}}.git
git remote -v
git push origin master
```

Reproducibility
---------------

Environment made with conda. To make an environment;

```bash
conda create --name {{cookiecutter.project_name}} python=3.7 ipykernel
```

### Export
This environment can be exported to a `.yml` file through the following command:

```bash
conda env export > environment.yml
```

Which creates the `.yml` file present in the root dir.


### Load
To recreate this environment, it suffices to run;

```bash
conda env create -f environment.yml -n {{cookiecutter.project_name}} 
```

Which presupposes a miniconda on your own machine.

### Add kernel to Jupyter

To add this python environment to the list of Jupyter environments, do the following. 
```bash
source activate {{cookiecutter.project_name}}
python -m ipykernel install --user --name {{cookiecutter.project_name}} --display-name "{{cookiecutter.project_name}}"
```

_N.b.: This requires ipykernel to be installed in the environment._

Dependency Managment
--------------------

For a pip install, you also need some kind of reproducibility. What matters there is the fact that you need to list your abstract dependencies. This needs to be done in the `setup.cfg` file.


Continuous Integration - Tests
------------------------------

Documentation
-------------

Install sphinx, if necessary. Obviously, no need to do this explicitly in your isolated environment, that will just bloat everything.

```bash
conda install sphinx
```

Then render the docs as

```bash
python setup.py docs
```

Publish
-------

To upload the final product to pip, first edit the `setup.cfg` file.
